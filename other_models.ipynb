{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "from IPython.core.display_functions import display\n",
    "from IPython.display import Audio\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "from music_plots import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<h1> Data management </h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tracks_df = load(\"data/tracks.csv\")\n",
    "genres_df = load(\"data/genres.csv\")\n",
    "features_df = load(\"data/features.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "          #tracks  parent          title  top_level\ngenre_id                                           \n1            8693      38    Avant-Garde         38\n2            5271       0  International          2\n3            1752       0          Blues          3\n4            4126       0           Jazz          4\n5            4106       0      Classical          5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#tracks</th>\n      <th>parent</th>\n      <th>title</th>\n      <th>top_level</th>\n    </tr>\n    <tr>\n      <th>genre_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>8693</td>\n      <td>38</td>\n      <td>Avant-Garde</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5271</td>\n      <td>0</td>\n      <td>International</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1752</td>\n      <td>0</td>\n      <td>Blues</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4126</td>\n      <td>0</td>\n      <td>Jazz</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4106</td>\n      <td>0</td>\n      <td>Classical</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.head()\n",
    "genres_df.head()\n",
    "#features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "track_id\n2             Hip-Hop\n3             Hip-Hop\n5             Hip-Hop\n10                Pop\n134           Hip-Hop\n             ...     \n95823    Experimental\n95831    Experimental\n95866    Experimental\n95868    Experimental\n95871    Experimental\nName: genre_top, Length: 32823, dtype: category\nCategories (16, object): ['Blues', 'Classical', 'Country', 'Easy Listening', ..., 'Pop', 'Rock', 'Soul-RnB', 'Spoken']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_genres = tracks_df.xs('track', level=0, axis=1)['genre_top'].loc[features_df.dropna().index]\n",
    "track_genres = track_genres.dropna()\n",
    "features_df = features_df.loc[track_genres.index]\n",
    "\n",
    "track_genres"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock                   10040\n",
      "Experimental            7039\n",
      "Electronic              6201\n",
      "Hip-Hop                 2086\n",
      "Folk                    1773\n",
      "Pop                     1411\n",
      "Classical               1007\n",
      "International            879\n",
      "Instrumental             797\n",
      "Jazz                     517\n",
      "Old-Time / Historic      414\n",
      "Spoken                   307\n",
      "Soul-RnB                 130\n",
      "Country                  118\n",
      "Blues                     89\n",
      "Easy Listening            15\n",
      "Name: genre_top, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_counts = track_genres.value_counts()\n",
    "print(value_counts)\n",
    "value_counts.plot.bar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hip-Hop': 0, 'Pop': 1, 'Rock': 2, 'Experimental': 3, 'Folk': 4, 'Jazz': 5, 'Electronic': 6, 'Spoken': 7, 'International': 8, 'Soul-RnB': 9, 'Blues': 10, 'Country': 11, 'Classical': 12, 'Old-Time / Historic': 13, 'Instrumental': 14, 'Easy Listening': 15}\n"
     ]
    }
   ],
   "source": [
    "# genres dictionary\n",
    "genres = {}\n",
    "index = 0\n",
    "for i in track_genres.unique():\n",
    "    genres[i] = index\n",
    "    index += 1\n",
    "print(genres)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32823\n",
      "32823\n"
     ]
    },
    {
     "data": {
      "text/plain": "feature    chroma_cens                                                    \\\nstatistics    kurtosis                                                     \nnumber              01        02        03        04        05        06   \ntrack_id                                                                   \n2             7.180653  5.230309  0.249321  1.347620  1.482478  0.531371   \n3             1.888963  0.760539  0.345297  2.295201  1.654031  0.067592   \n5             0.527563 -0.077654 -0.279610  0.685883  1.937570  0.880839   \n10            3.702245 -0.291193  2.196742 -0.234449  1.367364  0.998411   \n134           0.918445  0.674147  0.577818  1.281117  0.933746  0.078177   \n...                ...       ...       ...       ...       ...       ...   \n95823        -0.555692 -0.338323  0.883295  0.424315  1.450894  0.070183   \n95831        -0.612445  0.702932  0.776201  0.186624  0.580003  0.287438   \n95866         3.528371  4.667782  5.247205  4.168351  3.276534  4.309053   \n95868        -0.033556  0.271865  0.280602  0.560396  1.511805  0.710866   \n95871         5.215266  4.964749  0.824476  1.733783  2.557416  3.057908   \n\nfeature                                             ...   tonnetz            \\\nstatistics                                          ...       std             \nnumber            07        08        09        10  ...        04        05   \ntrack_id                                            ...                       \n2           1.481593  2.691455  0.866868  1.341231  ...  0.054125  0.012226   \n3           1.366848  1.054094  0.108103  0.619185  ...  0.063831  0.014212   \n5          -0.923192 -0.927232  0.666617  1.038546  ...  0.040730  0.012691   \n10          1.770694  1.604566  0.521217  1.982386  ...  0.074358  0.017952   \n134         1.199204 -0.175223  0.925482  1.438509  ...  0.058766  0.016322   \n...              ...       ...       ...       ...  ...       ...       ...   \n95823       0.716997  0.757623  0.300295  0.063043  ...  0.064474  0.012939   \n95831      -0.037945 -1.151037 -1.074581  0.307664  ...  0.072024  0.011513   \n95866       2.768949  3.115098  3.815794  3.940277  ...  0.031871  0.012202   \n95868       1.451442  0.742910  0.739932  0.844851  ...  0.055034  0.012744   \n95871       1.768616  3.665696  1.518494  1.523711  ...  0.058086  0.016176   \n\nfeature                     zcr                                          \\\nstatistics             kurtosis       max      mean    median       min   \nnumber            06         01        01        01        01        01   \ntrack_id                                                                  \n2           0.012111   5.758890  0.459473  0.085629  0.071289  0.000000   \n3           0.017740   2.824694  0.466309  0.084578  0.063965  0.000000   \n5           0.014759   6.808415  0.375000  0.053114  0.041504  0.000000   \n10          0.013921  21.434212  0.452148  0.077515  0.071777  0.000000   \n134         0.015819   4.731087  0.419434  0.064370  0.050781  0.000000   \n...              ...        ...       ...       ...       ...       ...   \n95823       0.013397   6.294609  0.230469  0.039246  0.032715  0.004883   \n95831       0.013774  -0.943706  0.441406  0.117571  0.106934  0.005371   \n95866       0.012386   1.357928  0.400391  0.135901  0.143066  0.000000   \n95868       0.013205  -0.223611  0.402344  0.173291  0.182617  0.000000   \n95871       0.013788   0.166801  0.561035  0.211801  0.218262  0.000000   \n\nfeature                         \nstatistics      skew       std  \nnumber            01        01  \ntrack_id                        \n2           2.089872  0.061448  \n3           1.716724  0.069330  \n5           2.193303  0.044861  \n10          3.542325  0.040800  \n134         1.806106  0.054623  \n...              ...       ...  \n95823       1.909812  0.026319  \n95831       0.452720  0.085089  \n95866      -0.795436  0.055681  \n95868      -0.706943  0.048163  \n95871      -0.058994  0.087301  \n\n[32823 rows x 518 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>feature</th>\n      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n      <th>...</th>\n      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n      <th colspan=\"7\" halign=\"left\">zcr</th>\n    </tr>\n    <tr>\n      <th>statistics</th>\n      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n      <th>...</th>\n      <th colspan=\"3\" halign=\"left\">std</th>\n      <th>kurtosis</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>min</th>\n      <th>skew</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>number</th>\n      <th>01</th>\n      <th>02</th>\n      <th>03</th>\n      <th>04</th>\n      <th>05</th>\n      <th>06</th>\n      <th>07</th>\n      <th>08</th>\n      <th>09</th>\n      <th>10</th>\n      <th>...</th>\n      <th>04</th>\n      <th>05</th>\n      <th>06</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n    </tr>\n    <tr>\n      <th>track_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>7.180653</td>\n      <td>5.230309</td>\n      <td>0.249321</td>\n      <td>1.347620</td>\n      <td>1.482478</td>\n      <td>0.531371</td>\n      <td>1.481593</td>\n      <td>2.691455</td>\n      <td>0.866868</td>\n      <td>1.341231</td>\n      <td>...</td>\n      <td>0.054125</td>\n      <td>0.012226</td>\n      <td>0.012111</td>\n      <td>5.758890</td>\n      <td>0.459473</td>\n      <td>0.085629</td>\n      <td>0.071289</td>\n      <td>0.000000</td>\n      <td>2.089872</td>\n      <td>0.061448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.888963</td>\n      <td>0.760539</td>\n      <td>0.345297</td>\n      <td>2.295201</td>\n      <td>1.654031</td>\n      <td>0.067592</td>\n      <td>1.366848</td>\n      <td>1.054094</td>\n      <td>0.108103</td>\n      <td>0.619185</td>\n      <td>...</td>\n      <td>0.063831</td>\n      <td>0.014212</td>\n      <td>0.017740</td>\n      <td>2.824694</td>\n      <td>0.466309</td>\n      <td>0.084578</td>\n      <td>0.063965</td>\n      <td>0.000000</td>\n      <td>1.716724</td>\n      <td>0.069330</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.527563</td>\n      <td>-0.077654</td>\n      <td>-0.279610</td>\n      <td>0.685883</td>\n      <td>1.937570</td>\n      <td>0.880839</td>\n      <td>-0.923192</td>\n      <td>-0.927232</td>\n      <td>0.666617</td>\n      <td>1.038546</td>\n      <td>...</td>\n      <td>0.040730</td>\n      <td>0.012691</td>\n      <td>0.014759</td>\n      <td>6.808415</td>\n      <td>0.375000</td>\n      <td>0.053114</td>\n      <td>0.041504</td>\n      <td>0.000000</td>\n      <td>2.193303</td>\n      <td>0.044861</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3.702245</td>\n      <td>-0.291193</td>\n      <td>2.196742</td>\n      <td>-0.234449</td>\n      <td>1.367364</td>\n      <td>0.998411</td>\n      <td>1.770694</td>\n      <td>1.604566</td>\n      <td>0.521217</td>\n      <td>1.982386</td>\n      <td>...</td>\n      <td>0.074358</td>\n      <td>0.017952</td>\n      <td>0.013921</td>\n      <td>21.434212</td>\n      <td>0.452148</td>\n      <td>0.077515</td>\n      <td>0.071777</td>\n      <td>0.000000</td>\n      <td>3.542325</td>\n      <td>0.040800</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>0.918445</td>\n      <td>0.674147</td>\n      <td>0.577818</td>\n      <td>1.281117</td>\n      <td>0.933746</td>\n      <td>0.078177</td>\n      <td>1.199204</td>\n      <td>-0.175223</td>\n      <td>0.925482</td>\n      <td>1.438509</td>\n      <td>...</td>\n      <td>0.058766</td>\n      <td>0.016322</td>\n      <td>0.015819</td>\n      <td>4.731087</td>\n      <td>0.419434</td>\n      <td>0.064370</td>\n      <td>0.050781</td>\n      <td>0.000000</td>\n      <td>1.806106</td>\n      <td>0.054623</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95823</th>\n      <td>-0.555692</td>\n      <td>-0.338323</td>\n      <td>0.883295</td>\n      <td>0.424315</td>\n      <td>1.450894</td>\n      <td>0.070183</td>\n      <td>0.716997</td>\n      <td>0.757623</td>\n      <td>0.300295</td>\n      <td>0.063043</td>\n      <td>...</td>\n      <td>0.064474</td>\n      <td>0.012939</td>\n      <td>0.013397</td>\n      <td>6.294609</td>\n      <td>0.230469</td>\n      <td>0.039246</td>\n      <td>0.032715</td>\n      <td>0.004883</td>\n      <td>1.909812</td>\n      <td>0.026319</td>\n    </tr>\n    <tr>\n      <th>95831</th>\n      <td>-0.612445</td>\n      <td>0.702932</td>\n      <td>0.776201</td>\n      <td>0.186624</td>\n      <td>0.580003</td>\n      <td>0.287438</td>\n      <td>-0.037945</td>\n      <td>-1.151037</td>\n      <td>-1.074581</td>\n      <td>0.307664</td>\n      <td>...</td>\n      <td>0.072024</td>\n      <td>0.011513</td>\n      <td>0.013774</td>\n      <td>-0.943706</td>\n      <td>0.441406</td>\n      <td>0.117571</td>\n      <td>0.106934</td>\n      <td>0.005371</td>\n      <td>0.452720</td>\n      <td>0.085089</td>\n    </tr>\n    <tr>\n      <th>95866</th>\n      <td>3.528371</td>\n      <td>4.667782</td>\n      <td>5.247205</td>\n      <td>4.168351</td>\n      <td>3.276534</td>\n      <td>4.309053</td>\n      <td>2.768949</td>\n      <td>3.115098</td>\n      <td>3.815794</td>\n      <td>3.940277</td>\n      <td>...</td>\n      <td>0.031871</td>\n      <td>0.012202</td>\n      <td>0.012386</td>\n      <td>1.357928</td>\n      <td>0.400391</td>\n      <td>0.135901</td>\n      <td>0.143066</td>\n      <td>0.000000</td>\n      <td>-0.795436</td>\n      <td>0.055681</td>\n    </tr>\n    <tr>\n      <th>95868</th>\n      <td>-0.033556</td>\n      <td>0.271865</td>\n      <td>0.280602</td>\n      <td>0.560396</td>\n      <td>1.511805</td>\n      <td>0.710866</td>\n      <td>1.451442</td>\n      <td>0.742910</td>\n      <td>0.739932</td>\n      <td>0.844851</td>\n      <td>...</td>\n      <td>0.055034</td>\n      <td>0.012744</td>\n      <td>0.013205</td>\n      <td>-0.223611</td>\n      <td>0.402344</td>\n      <td>0.173291</td>\n      <td>0.182617</td>\n      <td>0.000000</td>\n      <td>-0.706943</td>\n      <td>0.048163</td>\n    </tr>\n    <tr>\n      <th>95871</th>\n      <td>5.215266</td>\n      <td>4.964749</td>\n      <td>0.824476</td>\n      <td>1.733783</td>\n      <td>2.557416</td>\n      <td>3.057908</td>\n      <td>1.768616</td>\n      <td>3.665696</td>\n      <td>1.518494</td>\n      <td>1.523711</td>\n      <td>...</td>\n      <td>0.058086</td>\n      <td>0.016176</td>\n      <td>0.013788</td>\n      <td>0.166801</td>\n      <td>0.561035</td>\n      <td>0.211801</td>\n      <td>0.218262</td>\n      <td>0.000000</td>\n      <td>-0.058994</td>\n      <td>0.087301</td>\n    </tr>\n  </tbody>\n</table>\n<p>32823 rows Ã— 518 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(track_genres))\n",
    "print(len(features_df))\n",
    "features_df.isna().any()\n",
    "features_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# generate train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df.iloc[:8000], track_genres.iloc[:8000], test_size=0.4, random_state=42, stratify=track_genres.iloc[:8000])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df, track_genres, test_size=0.4, random_state=42, stratify=track_genres)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "lab_encoder.fit(y_train)\n",
    "\n",
    "y_train = lab_encoder.transform(y_train)\n",
    "y_test = lab_encoder.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def evaluate_classifier(x_tr, x_te, y_tr, y_te, model):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    prediction = model.predict(x_te)\n",
    "    print(prediction[:10])\n",
    "    print(y_te[:10])\n",
    "    proba_train = model.predict_proba(x_te)\n",
    "    # pd.DataFrame(proba_train, columns=list(np.unique(lab_encoder.inverse_transform(y_train))))\n",
    "    print(pd.DataFrame(proba_train))\n",
    "    print(classification_report(y_te, prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>PCA</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_data(train_set, test_set, n_components, to_scale=True):\n",
    "\n",
    "    if to_scale:\n",
    "        # scale x_data\n",
    "        data_scaler = StandardScaler()\n",
    "        data_scaler.fit(train_set)\n",
    "\n",
    "        train_set = data_scaler.transform(train_set)\n",
    "        test_set = data_scaler.transform(test_set)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(train_set)\n",
    "\n",
    "    train_set = pca.transform(train_set)\n",
    "    test_set = pca.transform(test_set)\n",
    "\n",
    "    return train_set, test_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.60354791  -0.58995119]\n",
      " [  4.40287103  -4.76999404]\n",
      " [ 10.45776958  17.50262319]\n",
      " ...\n",
      " [  4.34920137   0.47933985]\n",
      " [ -6.16308081  -9.56565025]\n",
      " [-18.17963718   5.65331263]]\n",
      "[[16.14085012  4.24116619]\n",
      " [-3.3647734  -3.46883393]\n",
      " [-9.18277    -9.81920198]\n",
      " ...\n",
      " [ 3.71246594  6.02444555]\n",
      " [ 2.56445225  0.46266584]\n",
      " [-1.83267166 -2.24538347]]\n",
      "[[  2.6035483   -0.58996835]\n",
      " [  4.40287072  -4.76996905]\n",
      " [ 10.45777044  17.50250499]\n",
      " ...\n",
      " [  4.34920135   0.47935106]\n",
      " [ -6.16308102  -9.56561957]\n",
      " [-18.1796375    5.65333079]]\n",
      "[[16.14085019  4.24116482]\n",
      " [-3.36477334 -3.46883368]\n",
      " [-9.18277001 -9.81920519]\n",
      " ...\n",
      " [ 3.71246608  6.0244212 ]\n",
      " [ 2.56445245  0.4626638 ]\n",
      " [-1.83267153 -2.24539663]]\n"
     ]
    }
   ],
   "source": [
    "# PCA test\n",
    "x_data, x_test,_,_ = train_test_split(features_df.iloc[:8000], track_genres.iloc[:8000], test_size=0.4, random_state=42, stratify=track_genres.iloc[:8000])\n",
    "\n",
    "# already scaled\n",
    "x, y = pca_data(X_train, X_test, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# to scale\n",
    "x, y = pca_data(x_data, x_test, 2, to_scale=True)\n",
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Model parametes tuning</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "def optimize_model(model, x_train, y_train, parameters, to_scale=False):\n",
    "    if to_scale:\n",
    "        x_train = StandardScaler().fit_transform(x_train)\n",
    "\n",
    "    #rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    #n_jobs=-1 use ll processors in parallel\n",
    "    gs = GridSearchCV(model, parameters, scoring='f1_micro', cv=2, return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "    gs.fit(x_train, y_train)\n",
    "\n",
    "    print(\"best parameters: \", gs.best_params_)\n",
    "    print(\"score: \", gs.best_score_)\n",
    "    return gs.best_estimator_\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>SVM</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "print(\"Without PCA\")\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, svm_model)\n",
    "\n",
    "pca_svm_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "print(\"With PCA\")\n",
    "pca_train, pca_test = pca_data(X_train, X_test, 2)\n",
    "print(pca_train, pca_test)\n",
    "evaluate_classifier(pca_train, pca_test, y_train, y_test, pca_svm_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SVM model evaluation\n",
    "param_evaluated = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]}\n",
    "\n",
    "svm_base_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "svm_best_model = optimize_model(svm_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test,svm_best_model)\n",
    "svm_best_model\n",
    "\n",
    "# After run\n",
    "# best parameters:  {'C': 100, 'gamma': 0.001}\n",
    "# score:  0.66625"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>K-nearest neighbors</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, knn_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KNN model evaluation\n",
    "leaf_size = list(range(1,10))\n",
    "n_neighbors = list(range(1,10))\n",
    "p=[1,2]\n",
    "param_evaluated = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "knn_base_model = KNeighborsClassifier()\n",
    "knn_best_model = optimize_model(knn_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, knn_best_model)\n",
    "knn_best_model\n",
    "\n",
    "# After run\n",
    "# best parameters:  {'leaf_size': 1, 'n_neighbors': 4, 'p': 1}\n",
    "# score:  0.5852083333333333"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Random forest</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, rf_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random forest model evaluation\n",
    "n_estimators = list(range(90, 101))\n",
    "\n",
    "param_evaluated = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': n_estimators}\n",
    "\n",
    "\"\"\"param_evaluated = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\"\"\"\n",
    "\n",
    "rf_base_model = RandomForestClassifier()\n",
    "rf_best_model = optimize_model(rf_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, rf_best_model)\n",
    "rf_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Naive bayes</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, nb_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# naive bayes model evaluation\n",
    "param_evaluated = {\n",
    "    'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "}\n",
    "\n",
    "nb_base_model = GaussianNB()\n",
    "nb_best_model = optimize_model(nb_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, nb_best_model)\n",
    "nb_best_model\n",
    "\n",
    "# After run\n",
    "# best parameters:  {'var_smoothing': 0.01}\n",
    "#score:  0.3989583333333333"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Neural network</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(features_df, track_genres, train_size=0.8, random_state=42, stratify=track_genres)\n",
    "\n",
    "# Split remaining dataset in test and validation\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "print(f\"Training has {len(X_train), len(y_train)}, Validation has {len(X_valid), len(y_valid)}, Testing has {len(X_test), len(y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "lab_encoder.fit(y_train)\n",
    "\n",
    "y_train = lab_encoder.transform(y_train)\n",
    "y_valid = lab_encoder.transform(y_valid)\n",
    "y_test = lab_encoder.transform(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, activation='relu', input_shape=(518,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(len(y_train[1]))\n",
    "model.add(Dense(len(y_train[1]), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, callbacks=[early_stop, PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, activation='relu', input_shape=(518,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(len(y_train[1]))\n",
    "model.add(Dense(len(y_train[1]), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, callbacks=[early_stop, PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(hp_units1, activation='relu', input_shape=(518,)))\n",
    "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(hp_units2, activation='relu'))\n",
    "\n",
    "    model.add(Dense(len(y_train[1]), activation='softmax'))\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_data=(X_valid, y_valid), callbacks=[PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hypermodel.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}