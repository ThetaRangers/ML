{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "from IPython.core.display_functions import display\n",
    "from IPython.display import Audio\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "from music_plots import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<h1> Data management </h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tracks_df = load(\"data/tracks.csv\")\n",
    "genres_df = load(\"data/genres.csv\")\n",
    "features_df = load(\"data/features.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "          #tracks  parent          title  top_level\ngenre_id                                           \n1            8693      38    Avant-Garde         38\n2            5271       0  International          2\n3            1752       0          Blues          3\n4            4126       0           Jazz          4\n5            4106       0      Classical          5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#tracks</th>\n      <th>parent</th>\n      <th>title</th>\n      <th>top_level</th>\n    </tr>\n    <tr>\n      <th>genre_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>8693</td>\n      <td>38</td>\n      <td>Avant-Garde</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5271</td>\n      <td>0</td>\n      <td>International</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1752</td>\n      <td>0</td>\n      <td>Blues</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4126</td>\n      <td>0</td>\n      <td>Jazz</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4106</td>\n      <td>0</td>\n      <td>Classical</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.head()\n",
    "genres_df.head()\n",
    "#features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "track_id\n2         Hip-Hop\n3         Hip-Hop\n5         Hip-Hop\n10            Pop\n134       Hip-Hop\n           ...   \n155315       Rock\n155316       Rock\n155317       Rock\n155318       Rock\n155319       Rock\nName: genre_top, Length: 49598, dtype: category\nCategories (16, object): ['Blues', 'Classical', 'Country', 'Easy Listening', ..., 'Pop', 'Rock', 'Soul-RnB', 'Spoken']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_genres = tracks_df.xs('track', level=0, axis=1)['genre_top'].loc[features_df.dropna().index]\n",
    "track_genres = track_genres.dropna()\n",
    "features_df = features_df.loc[track_genres.index]\n",
    "\n",
    "track_genres"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock                   14182\n",
      "Experimental           10608\n",
      "Electronic              9372\n",
      "Hip-Hop                 3552\n",
      "Folk                    2803\n",
      "Pop                     2332\n",
      "Instrumental            2079\n",
      "International           1389\n",
      "Classical               1230\n",
      "Jazz                     571\n",
      "Old-Time / Historic      554\n",
      "Spoken                   423\n",
      "Country                  194\n",
      "Soul-RnB                 175\n",
      "Blues                    110\n",
      "Easy Listening            24\n",
      "Name: genre_top, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_counts = track_genres.value_counts()\n",
    "print(value_counts)\n",
    "value_counts.plot.bar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hip-Hop': 0, 'Pop': 1, 'Rock': 2, 'Experimental': 3, 'Folk': 4, 'Jazz': 5, 'Electronic': 6, 'Spoken': 7, 'International': 8, 'Soul-RnB': 9, 'Blues': 10, 'Country': 11, 'Classical': 12, 'Old-Time / Historic': 13, 'Instrumental': 14, 'Easy Listening': 15}\n"
     ]
    }
   ],
   "source": [
    "# genres dictionary\n",
    "genres = {}\n",
    "index = 0\n",
    "for i in track_genres.unique():\n",
    "    genres[i] = index\n",
    "    index += 1\n",
    "print(genres)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32823\n",
      "32823\n"
     ]
    },
    {
     "data": {
      "text/plain": "feature    chroma_cens                                                    \\\nstatistics    kurtosis                                                     \nnumber              01        02        03        04        05        06   \ntrack_id                                                                   \n2             7.180653  5.230309  0.249321  1.347620  1.482478  0.531371   \n3             1.888963  0.760539  0.345297  2.295201  1.654031  0.067592   \n5             0.527563 -0.077654 -0.279610  0.685883  1.937570  0.880839   \n10            3.702245 -0.291193  2.196742 -0.234449  1.367364  0.998411   \n134           0.918445  0.674147  0.577818  1.281117  0.933746  0.078177   \n...                ...       ...       ...       ...       ...       ...   \n95823        -0.555692 -0.338323  0.883295  0.424315  1.450894  0.070183   \n95831        -0.612445  0.702932  0.776201  0.186624  0.580003  0.287438   \n95866         3.528371  4.667782  5.247205  4.168351  3.276534  4.309053   \n95868        -0.033556  0.271865  0.280602  0.560396  1.511805  0.710866   \n95871         5.215266  4.964749  0.824476  1.733783  2.557416  3.057908   \n\nfeature                                             ...   tonnetz            \\\nstatistics                                          ...       std             \nnumber            07        08        09        10  ...        04        05   \ntrack_id                                            ...                       \n2           1.481593  2.691455  0.866868  1.341231  ...  0.054125  0.012226   \n3           1.366848  1.054094  0.108103  0.619185  ...  0.063831  0.014212   \n5          -0.923192 -0.927232  0.666617  1.038546  ...  0.040730  0.012691   \n10          1.770694  1.604566  0.521217  1.982386  ...  0.074358  0.017952   \n134         1.199204 -0.175223  0.925482  1.438509  ...  0.058766  0.016322   \n...              ...       ...       ...       ...  ...       ...       ...   \n95823       0.716997  0.757623  0.300295  0.063043  ...  0.064474  0.012939   \n95831      -0.037945 -1.151037 -1.074581  0.307664  ...  0.072024  0.011513   \n95866       2.768949  3.115098  3.815794  3.940277  ...  0.031871  0.012202   \n95868       1.451442  0.742910  0.739932  0.844851  ...  0.055034  0.012744   \n95871       1.768616  3.665696  1.518494  1.523711  ...  0.058086  0.016176   \n\nfeature                     zcr                                          \\\nstatistics             kurtosis       max      mean    median       min   \nnumber            06         01        01        01        01        01   \ntrack_id                                                                  \n2           0.012111   5.758890  0.459473  0.085629  0.071289  0.000000   \n3           0.017740   2.824694  0.466309  0.084578  0.063965  0.000000   \n5           0.014759   6.808415  0.375000  0.053114  0.041504  0.000000   \n10          0.013921  21.434212  0.452148  0.077515  0.071777  0.000000   \n134         0.015819   4.731087  0.419434  0.064370  0.050781  0.000000   \n...              ...        ...       ...       ...       ...       ...   \n95823       0.013397   6.294609  0.230469  0.039246  0.032715  0.004883   \n95831       0.013774  -0.943706  0.441406  0.117571  0.106934  0.005371   \n95866       0.012386   1.357928  0.400391  0.135901  0.143066  0.000000   \n95868       0.013205  -0.223611  0.402344  0.173291  0.182617  0.000000   \n95871       0.013788   0.166801  0.561035  0.211801  0.218262  0.000000   \n\nfeature                         \nstatistics      skew       std  \nnumber            01        01  \ntrack_id                        \n2           2.089872  0.061448  \n3           1.716724  0.069330  \n5           2.193303  0.044861  \n10          3.542325  0.040800  \n134         1.806106  0.054623  \n...              ...       ...  \n95823       1.909812  0.026319  \n95831       0.452720  0.085089  \n95866      -0.795436  0.055681  \n95868      -0.706943  0.048163  \n95871      -0.058994  0.087301  \n\n[32823 rows x 518 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>feature</th>\n      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n      <th>...</th>\n      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n      <th colspan=\"7\" halign=\"left\">zcr</th>\n    </tr>\n    <tr>\n      <th>statistics</th>\n      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n      <th>...</th>\n      <th colspan=\"3\" halign=\"left\">std</th>\n      <th>kurtosis</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>min</th>\n      <th>skew</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>number</th>\n      <th>01</th>\n      <th>02</th>\n      <th>03</th>\n      <th>04</th>\n      <th>05</th>\n      <th>06</th>\n      <th>07</th>\n      <th>08</th>\n      <th>09</th>\n      <th>10</th>\n      <th>...</th>\n      <th>04</th>\n      <th>05</th>\n      <th>06</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n      <th>01</th>\n    </tr>\n    <tr>\n      <th>track_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>7.180653</td>\n      <td>5.230309</td>\n      <td>0.249321</td>\n      <td>1.347620</td>\n      <td>1.482478</td>\n      <td>0.531371</td>\n      <td>1.481593</td>\n      <td>2.691455</td>\n      <td>0.866868</td>\n      <td>1.341231</td>\n      <td>...</td>\n      <td>0.054125</td>\n      <td>0.012226</td>\n      <td>0.012111</td>\n      <td>5.758890</td>\n      <td>0.459473</td>\n      <td>0.085629</td>\n      <td>0.071289</td>\n      <td>0.000000</td>\n      <td>2.089872</td>\n      <td>0.061448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.888963</td>\n      <td>0.760539</td>\n      <td>0.345297</td>\n      <td>2.295201</td>\n      <td>1.654031</td>\n      <td>0.067592</td>\n      <td>1.366848</td>\n      <td>1.054094</td>\n      <td>0.108103</td>\n      <td>0.619185</td>\n      <td>...</td>\n      <td>0.063831</td>\n      <td>0.014212</td>\n      <td>0.017740</td>\n      <td>2.824694</td>\n      <td>0.466309</td>\n      <td>0.084578</td>\n      <td>0.063965</td>\n      <td>0.000000</td>\n      <td>1.716724</td>\n      <td>0.069330</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.527563</td>\n      <td>-0.077654</td>\n      <td>-0.279610</td>\n      <td>0.685883</td>\n      <td>1.937570</td>\n      <td>0.880839</td>\n      <td>-0.923192</td>\n      <td>-0.927232</td>\n      <td>0.666617</td>\n      <td>1.038546</td>\n      <td>...</td>\n      <td>0.040730</td>\n      <td>0.012691</td>\n      <td>0.014759</td>\n      <td>6.808415</td>\n      <td>0.375000</td>\n      <td>0.053114</td>\n      <td>0.041504</td>\n      <td>0.000000</td>\n      <td>2.193303</td>\n      <td>0.044861</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3.702245</td>\n      <td>-0.291193</td>\n      <td>2.196742</td>\n      <td>-0.234449</td>\n      <td>1.367364</td>\n      <td>0.998411</td>\n      <td>1.770694</td>\n      <td>1.604566</td>\n      <td>0.521217</td>\n      <td>1.982386</td>\n      <td>...</td>\n      <td>0.074358</td>\n      <td>0.017952</td>\n      <td>0.013921</td>\n      <td>21.434212</td>\n      <td>0.452148</td>\n      <td>0.077515</td>\n      <td>0.071777</td>\n      <td>0.000000</td>\n      <td>3.542325</td>\n      <td>0.040800</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>0.918445</td>\n      <td>0.674147</td>\n      <td>0.577818</td>\n      <td>1.281117</td>\n      <td>0.933746</td>\n      <td>0.078177</td>\n      <td>1.199204</td>\n      <td>-0.175223</td>\n      <td>0.925482</td>\n      <td>1.438509</td>\n      <td>...</td>\n      <td>0.058766</td>\n      <td>0.016322</td>\n      <td>0.015819</td>\n      <td>4.731087</td>\n      <td>0.419434</td>\n      <td>0.064370</td>\n      <td>0.050781</td>\n      <td>0.000000</td>\n      <td>1.806106</td>\n      <td>0.054623</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95823</th>\n      <td>-0.555692</td>\n      <td>-0.338323</td>\n      <td>0.883295</td>\n      <td>0.424315</td>\n      <td>1.450894</td>\n      <td>0.070183</td>\n      <td>0.716997</td>\n      <td>0.757623</td>\n      <td>0.300295</td>\n      <td>0.063043</td>\n      <td>...</td>\n      <td>0.064474</td>\n      <td>0.012939</td>\n      <td>0.013397</td>\n      <td>6.294609</td>\n      <td>0.230469</td>\n      <td>0.039246</td>\n      <td>0.032715</td>\n      <td>0.004883</td>\n      <td>1.909812</td>\n      <td>0.026319</td>\n    </tr>\n    <tr>\n      <th>95831</th>\n      <td>-0.612445</td>\n      <td>0.702932</td>\n      <td>0.776201</td>\n      <td>0.186624</td>\n      <td>0.580003</td>\n      <td>0.287438</td>\n      <td>-0.037945</td>\n      <td>-1.151037</td>\n      <td>-1.074581</td>\n      <td>0.307664</td>\n      <td>...</td>\n      <td>0.072024</td>\n      <td>0.011513</td>\n      <td>0.013774</td>\n      <td>-0.943706</td>\n      <td>0.441406</td>\n      <td>0.117571</td>\n      <td>0.106934</td>\n      <td>0.005371</td>\n      <td>0.452720</td>\n      <td>0.085089</td>\n    </tr>\n    <tr>\n      <th>95866</th>\n      <td>3.528371</td>\n      <td>4.667782</td>\n      <td>5.247205</td>\n      <td>4.168351</td>\n      <td>3.276534</td>\n      <td>4.309053</td>\n      <td>2.768949</td>\n      <td>3.115098</td>\n      <td>3.815794</td>\n      <td>3.940277</td>\n      <td>...</td>\n      <td>0.031871</td>\n      <td>0.012202</td>\n      <td>0.012386</td>\n      <td>1.357928</td>\n      <td>0.400391</td>\n      <td>0.135901</td>\n      <td>0.143066</td>\n      <td>0.000000</td>\n      <td>-0.795436</td>\n      <td>0.055681</td>\n    </tr>\n    <tr>\n      <th>95868</th>\n      <td>-0.033556</td>\n      <td>0.271865</td>\n      <td>0.280602</td>\n      <td>0.560396</td>\n      <td>1.511805</td>\n      <td>0.710866</td>\n      <td>1.451442</td>\n      <td>0.742910</td>\n      <td>0.739932</td>\n      <td>0.844851</td>\n      <td>...</td>\n      <td>0.055034</td>\n      <td>0.012744</td>\n      <td>0.013205</td>\n      <td>-0.223611</td>\n      <td>0.402344</td>\n      <td>0.173291</td>\n      <td>0.182617</td>\n      <td>0.000000</td>\n      <td>-0.706943</td>\n      <td>0.048163</td>\n    </tr>\n    <tr>\n      <th>95871</th>\n      <td>5.215266</td>\n      <td>4.964749</td>\n      <td>0.824476</td>\n      <td>1.733783</td>\n      <td>2.557416</td>\n      <td>3.057908</td>\n      <td>1.768616</td>\n      <td>3.665696</td>\n      <td>1.518494</td>\n      <td>1.523711</td>\n      <td>...</td>\n      <td>0.058086</td>\n      <td>0.016176</td>\n      <td>0.013788</td>\n      <td>0.166801</td>\n      <td>0.561035</td>\n      <td>0.211801</td>\n      <td>0.218262</td>\n      <td>0.000000</td>\n      <td>-0.058994</td>\n      <td>0.087301</td>\n    </tr>\n  </tbody>\n</table>\n<p>32823 rows × 518 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(track_genres))\n",
    "print(len(features_df))\n",
    "features_df.isna().any()\n",
    "features_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# generate train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df.iloc[:8000], track_genres.iloc[:8000], test_size=0.4, random_state=42, stratify=track_genres.iloc[:8000])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df, track_genres, test_size=0.4, random_state=42, stratify=track_genres)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "lab_encoder.fit(y_train)\n",
    "\n",
    "y_train = lab_encoder.transform(y_train)\n",
    "y_test = lab_encoder.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def evaluate_classifier(x_tr, x_te, y_tr, y_te, model):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    prediction = model.predict(x_te)\n",
    "    print(prediction[:10])\n",
    "    print(y_te[:10])\n",
    "    proba_train = model.predict_proba(x_te)\n",
    "    # pd.DataFrame(proba_train, columns=list(np.unique(lab_encoder.inverse_transform(y_train))))\n",
    "    print(pd.DataFrame(proba_train))\n",
    "    print(classification_report(y_te, prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>PCA</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_data(train_set, test_set, n_components, to_scale=True):\n",
    "\n",
    "    if to_scale:\n",
    "        # scale x_data\n",
    "        data_scaler = StandardScaler()\n",
    "        data_scaler.fit(train_set)\n",
    "\n",
    "        train_set = data_scaler.transform(train_set)\n",
    "        test_set = data_scaler.transform(test_set)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(train_set)\n",
    "\n",
    "    train_set = pca.transform(train_set)\n",
    "    test_set = pca.transform(test_set)\n",
    "\n",
    "    return train_set, test_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.60354791  -0.58995119]\n",
      " [  4.40287103  -4.76999404]\n",
      " [ 10.45776958  17.50262319]\n",
      " ...\n",
      " [  4.34920137   0.47933985]\n",
      " [ -6.16308081  -9.56565025]\n",
      " [-18.17963718   5.65331263]]\n",
      "[[16.14085012  4.24116619]\n",
      " [-3.3647734  -3.46883393]\n",
      " [-9.18277    -9.81920198]\n",
      " ...\n",
      " [ 3.71246594  6.02444555]\n",
      " [ 2.56445225  0.46266584]\n",
      " [-1.83267166 -2.24538347]]\n",
      "[[  2.6035483   -0.58996835]\n",
      " [  4.40287072  -4.76996905]\n",
      " [ 10.45777044  17.50250499]\n",
      " ...\n",
      " [  4.34920135   0.47935106]\n",
      " [ -6.16308102  -9.56561957]\n",
      " [-18.1796375    5.65333079]]\n",
      "[[16.14085019  4.24116482]\n",
      " [-3.36477334 -3.46883368]\n",
      " [-9.18277001 -9.81920519]\n",
      " ...\n",
      " [ 3.71246608  6.0244212 ]\n",
      " [ 2.56445245  0.4626638 ]\n",
      " [-1.83267153 -2.24539663]]\n"
     ]
    }
   ],
   "source": [
    "# PCA test\n",
    "x_data, x_test,_,_ = train_test_split(features_df.iloc[:8000], track_genres.iloc[:8000], test_size=0.4, random_state=42, stratify=track_genres.iloc[:8000])\n",
    "\n",
    "# already scaled\n",
    "x, y = pca_data(X_train, X_test, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# to scale\n",
    "x, y = pca_data(x_data, x_test, 2, to_scale=True)\n",
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Model parametes tuning</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "def optimize_model(model, x_train, y_train, parameters, to_scale=False):\n",
    "    if to_scale:\n",
    "        x_train = StandardScaler().fit_transform(x_train)\n",
    "\n",
    "    #rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    #n_jobs=-1 use ll processors in parallel\n",
    "    gs = GridSearchCV(model, parameters, scoring='f1_micro', cv=2, return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "    gs.fit(x_train, y_train)\n",
    "\n",
    "    print(\"best parameters: \", gs.best_params_)\n",
    "    print(\"score: \", gs.best_score_)\n",
    "    return gs.best_estimator_\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>SVM</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "print(\"Without PCA\")\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, svm_model)\n",
    "\n",
    "pca_svm_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "print(\"With PCA\")\n",
    "pca_train, pca_test = pca_data(X_train, X_test, 2)\n",
    "print(pca_train, pca_test)\n",
    "evaluate_classifier(pca_train, pca_test, y_train, y_test, pca_svm_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SVM model evaluation\n",
    "param_evaluated = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]}\n",
    "\n",
    "svm_base_model = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "svm_best_model = optimize_model(svm_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test,svm_best_model)\n",
    "svm_best_model\n",
    "\n",
    "# After run\n",
    "# best parameters:  {'C': 100, 'gamma': 0.001}\n",
    "# score:  0.66625"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>K-nearest neighbors</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, knn_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KNN model evaluation\n",
    "leaf_size = list(range(1,10))\n",
    "n_neighbors = list(range(1,10))\n",
    "p=[1,2]\n",
    "param_evaluated = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "knn_base_model = KNeighborsClassifier()\n",
    "knn_best_model = optimize_model(knn_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, knn_best_model)\n",
    "knn_best_model\n",
    "\n",
    "# After run\n",
    "# best parameters:  {'leaf_size': 1, 'n_neighbors': 4, 'p': 1}\n",
    "# score:  0.5852083333333333"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Random forest</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, rf_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random forest model evaluation\n",
    "n_estimators = list(range(90, 101))\n",
    "\n",
    "param_evaluated = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': n_estimators}\n",
    "\n",
    "\"\"\"param_evaluated = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\"\"\"\n",
    "\n",
    "rf_base_model = RandomForestClassifier()\n",
    "rf_best_model = optimize_model(rf_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, rf_best_model)\n",
    "rf_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Naive bayes</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, nb_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# naive bayes model evaluation\n",
    "param_evaluated = {\n",
    "    'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "}\n",
    "\n",
    "nb_base_model = GaussianNB()\n",
    "nb_best_model = optimize_model(nb_base_model, X_train, y_train, param_evaluated)\n",
    "evaluate_classifier(X_train, X_test, y_train, y_test, nb_best_model)\n",
    "nb_best_model\n",
    "\n",
    "# After run\n",
    "# best parameters:  {'var_smoothing': 0.01}\n",
    "#score:  0.3989583333333333"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Neural network</h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has (39678, 39678), Validation has (4960, 4960), Testing has (4960, 4960)\n"
     ]
    }
   ],
   "source": [
    "# Split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(features_df, track_genres, train_size=0.8, random_state=42, stratify=track_genres)\n",
    "\n",
    "# Split remaining dataset in test and validation\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "print(f\"Training has {len(X_train), len(y_train)}, Validation has {len(X_valid), len(y_valid)}, Testing has {len(X_test), len(y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "((39678, 518), (39678, 16), (4960, 518), (4960, 16), (4960, 518), (4960, 16))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "lab_encoder.fit(y_train)\n",
    "\n",
    "y_train = lab_encoder.transform(y_train)\n",
    "y_valid = lab_encoder.transform(y_valid)\n",
    "y_test = lab_encoder.transform(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, activation='relu', input_shape=(518,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(len(y_train[1]))\n",
    "model.add(Dense(len(y_train[1]), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, callbacks=[early_stop, PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, activation='relu', input_shape=(518,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(len(y_train[1]))\n",
    "model.add(Dense(len(y_train[1]), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, callbacks=[early_stop, PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 288 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(hp_units1, activation='relu', input_shape=(518,)))\n",
    "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(hp_units2, activation='relu'))\n",
    "\n",
    "    model.add(Dense(len(y_train[1]), activation='softmax'))\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units1')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 288)               149472    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 448)               129472    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                7184      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,128\n",
      "Trainable params: 286,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      " 202/1240 [===>..........................] - ETA: 8s - loss: 0.9706 - accuracy: 0.6860"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#model = tuner.hypermodel.build(best_hps)\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39msummary())\n\u001B[0;32m----> 4\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_valid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m val_acc_per_epoch \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      7\u001B[0m best_epoch \u001B[38;5;241m=\u001B[39m val_acc_per_epoch\u001B[38;5;241m.\u001B[39mindex(\u001B[38;5;28mmax\u001B[39m(val_acc_per_epoch)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2451\u001B[0m   (graph_function,\n\u001B[1;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1863\u001B[0m     args,\n\u001B[1;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1865\u001B[0m     executing_eagerly)\n\u001B[1;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_data=(X_valid, y_valid), callbacks=[PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hypermodel.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}