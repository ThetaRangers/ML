{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "from IPython.core.display_functions import display\n",
    "from IPython.display import Audio\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "from music_plots import *\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "files = os.listdir('data/spectrograms')\n",
    "tracks_df = load(\"data/tracks.csv\")\n",
    "genres_df = load(\"data/genres.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "track_ids = []\n",
    "print(files)\n",
    "for file in tqdm(files):\n",
    "    pre, ext = os.path.splitext(file)\n",
    "    track_ids.append(int(pre))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_tracks = tracks_df.xs('track', level=0, axis=1)['genre_top'].loc[track_ids]\n",
    "filtered_tracks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genres = {}\n",
    "tmp_x = 0\n",
    "#Assign value for the genres\n",
    "#for i in genres_df[genres_df['parent']==0]['title'].unique():\n",
    "for i in filtered_tracks.unique():\n",
    "    genres[i] = tmp_x\n",
    "    tmp_x = tmp_x + 1\n",
    "\n",
    "print(genres)\n",
    "genres_df[genres_df['parent']==0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Split dataset into chunks\n",
    "train_ds = filtered_tracks.sample(frac = 0.8)\n",
    "\n",
    "tmp_ds = filtered_tracks.drop(train_ds.index)\n",
    "validation_ds = tmp_ds.sample(frac = 0.5)\n",
    "test_ds = tmp_ds.drop(validation_ds.index)\n",
    "\n",
    "print(f\"Training has {len(train_ds)}, Validation has {len(validation_ds)}, Testing has {len(test_ds)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "tf_train_data = pd.DataFrame(columns=['Filename', 'label'])\n",
    "tf_validation_data = pd.DataFrame(columns=['Filename', 'label'])\n",
    "tf_test_data = pd.DataFrame(columns=['Filename', 'label'])\n",
    "for i in tqdm(train_ds.index):\n",
    "    tf_train_data.loc[i]=[\"data/spectrograms/\" + str(i) + \".png\", genres[train_ds.loc[i]]]\n",
    "\n",
    "for i in tqdm(validation_ds.index):\n",
    "    tf_validation_data.loc[i]=[\"data/spectrograms/\" + str(i) + \".png\", genres[validation_ds.loc[i]]]\n",
    "\n",
    "for i in tqdm(test_ds.index):\n",
    "    tf_test_data.loc[i]=[\"data/spectrograms/\" + str(i) + \".png\", genres[test_ds.loc[i]]]\n",
    "#genres[test_ds.loc[i]]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_validation_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tf_train_data = pd.DataFrame({'image': training_data, 'label': training_labels}, columns=['image', 'label'])\n",
    "tf_train_data.loc[2]\n",
    "#filtered_tracks.loc[2]\n",
    "#genres['Hip-Hop']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1 / 255.,           # normalize pixel values between 0-1\n",
    "    vertical_flip=False,         # vertical transposition\n",
    "    horizontal_flip=True,       # horizontal transposition\n",
    "    rotation_range=0,\n",
    "    height_shift_range=0.3,     # shift the height of the image 30%\n",
    "    brightness_range=[0.1, 0.9] # specify the range in which to decrease/increase brightness\n",
    ")\n",
    "\n",
    "validation_generator = ImageDataGenerator(\n",
    "    rescale=1 / 255.,           # normalize pixel values between 0-1\n",
    "    vertical_flip=False,         # vertical transposition\n",
    "    horizontal_flip=True,       # horizontal transposition\n",
    "    rotation_range=0,\n",
    "    height_shift_range=0.3,     # shift the height of the image 30%\n",
    "    brightness_range=[0.1, 0.9] # specify the range in which to decrease/increase brightness\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1 / 255.,           # normalize pixel values between 0-1\n",
    "    rotation_range=0\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "print(list(genres.keys()))\n",
    "\n",
    "traingen = train_generator.flow_from_dataframe(tf_train_data,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               subset='training',\n",
    "                                               shuffle=True,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               target_size=(174,484),\n",
    "                                               seed=42)\n",
    "\n",
    "validationgen = validation_generator.flow_from_dataframe(tf_validation_data,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               subset='training',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                                         target_size=(174,484),\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_generator.flow_from_dataframe(tf_test_data,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               subset='training',\n",
    "                                               shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             target_size=(174,484),\n",
    "                                               seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def model2hp(hp):\n",
    "    md = keras.Sequential()\n",
    "    md.add(keras.Input(shape=(174, 484, 3)))\n",
    "    hp_size = hp.Int('size', min_value=128, max_value=512, step=128)\n",
    "    md.add(layers.Resizing(hp_size, hp_size))\n",
    "\n",
    "    md.add(layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    md.add(layers.BatchNormalization())\n",
    "    md.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    md.add(layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    md.add(layers.BatchNormalization())\n",
    "    md.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    md.add(layers.Conv2D(128, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    md.add(layers.BatchNormalization())\n",
    "    md.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    md.add(layers.Conv2D(128, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    md.add(layers.BatchNormalization())\n",
    "    md.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    md.add(layers.Flatten())\n",
    "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
    "    md.add(layers.Dense(hp_units1, activation='relu'))\n",
    "\n",
    "    hp_dropout1 = hp.Float('dropout1', min_value=0.1, max_value=0.9, step=0.1)\n",
    "    md.add(layers.Dropout(hp_dropout1))\n",
    "    md.add(layers.Dense(8, activation=\"softmax\"))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    md.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return md\n",
    "\n",
    "tuner = kt.Hyperband(model2hp,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     factor=3,\n",
    "                     directory='my_dir_2',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(validationgen, validation_data=validationgen, epochs=50, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Units: {best_hps.get('units1')}\n",
    "Dropout:{best_hps.get('dropout1')}\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "Size: {best_hps.get('size')}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model2(width, height, depth, classes):\n",
    "    return keras.Sequential([\n",
    "        keras.Input(shape=(height, width, depth)),\n",
    "        layers.Resizing(128, 128),\n",
    "\n",
    "        layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        # Adding this layer\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(classes, activation=\"softmax\")\n",
    "    ])\n",
    "model = model2(\n",
    "    width=484, height=174,\n",
    "    depth=3, classes=len(genres))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_input = Input(shape=(174,484,3))\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=new_input)\n",
    "#base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "base_model.trainable = False ## Not trainable weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_model(input_shape, n_classes, fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "\n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "\n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet',\n",
    "                     input_shape=input_shape)\n",
    "\n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    md = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    return md\n",
    "\n",
    "model_vgg = create_model((174,484,3), 8)\n",
    "\n",
    "#print(\"==============BASE MODEL==============\")\n",
    "#print(base_model.summary())\n",
    "print(\"==============NEW MODEL===============\")\n",
    "print(model_vgg.summary())\n",
    "\n",
    "model_vgg.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import Model\n",
    "\n",
    "def create_model_kt(hp):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "\n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "\n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet',\n",
    "                     input_shape=(174,484,3))\n",
    "\n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    hp_fine_tune = hp.Int('included_layers', min_value=0, max_value=10, step=1)\n",
    "    if hp_fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-hp_fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "\n",
    "    hp_units1 = hp.Int('units1', min_value=100, max_value=4096, step=100)\n",
    "    top_model = Dense(hp_units1, activation='relu')(top_model)\n",
    "    hp_dropout1 = hp.Float('dropout1', min_value=0.1, max_value=0.9, step=0.1)\n",
    "    top_model = Dropout(hp_dropout1)(top_model)\n",
    "\n",
    "    hp_units2 = hp.Int('units2', min_value=100, max_value=1000, step=100)\n",
    "    top_model = Dense(hp_units2, activation='relu')(top_model)\n",
    "    hp_dropout2 = hp.Float('dropout2', min_value=0.1, max_value=0.9, step=0.1)\n",
    "    top_model = Dropout(hp_dropout2)(top_model)\n",
    "\n",
    "    output_layer = Dense(8, activation='softmax')(top_model)\n",
    "\n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    md = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    md.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return md\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(create_model_kt,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir_vgg',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(validationgen, validation_data=validationgen, epochs=10, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Included: {best_hps.get('included_layers')}\n",
    "Units1: {best_hps.get('units1')}\n",
    "Dropout1:{best_hps.get('dropout1')}\n",
    "Units2: {best_hps.get('units2')}\n",
    "Dropout2:{best_hps.get('dropout2')}\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "Size: {best_hps.get('size')}\n",
    "\"\"\")\n",
    "\n",
    "model_spec = tuner.hypermodel.build(best_hps)\n",
    "print(model_spec.summary())\n",
    "keras.utils.plot_model(model_spec, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model_vgg.fit(traingen, validation_data=validationgen, epochs=10, batch_size=64, callbacks=[early_stop, PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(\"dataset/Rock/87121.png\")\n",
    "image = img_to_array(image)\n",
    "grr = [image]\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(\"dataset/Electronic/20667.png\")\n",
    "image = img_to_array(image)\n",
    "grr.append(image)\n",
    "\n",
    "grr = np.array(grr, dtype=\"float\") / 255.0\n",
    "\n",
    "print(genres)\n",
    "\n",
    "prediction = model_vgg.predict(grr)\n",
    "\n",
    "display(Audio('data/tracks_wav//020667.wav', rate=22500))\n",
    "pd.DataFrame(prediction, columns=list(genres.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = model_vgg.predict(testgen)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "\n",
    "\n",
    "number_of_examples = len(testgen.filenames)\n",
    "number_of_generator_calls = math.ceil(number_of_examples / (1.0 * BATCH_SIZE))\n",
    "# 1.0 above is to skip integer division\n",
    "\n",
    "test_labels = []\n",
    "\n",
    "for i in range(0,int(number_of_generator_calls)):\n",
    "    test_labels.extend(np.array(testgen[i][1]))\n",
    "cm = confusion_matrix(test_labels, pred.argmax(axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "f = plt.figure(figsize=(15,15))\n",
    "ax= f.add_subplot()\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "ax.xaxis.set_ticklabels(list(genres.keys()))\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.yaxis.set_ticklabels(list(genres.keys()));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_train_data_chroma = pd.DataFrame(columns=['Filename', 'label'])\n",
    "tf_validation_data_chroma = pd.DataFrame(columns=['Filename', 'label'])\n",
    "tf_test_data_chroma = pd.DataFrame(columns=['Filename', 'label'])\n",
    "for i in tqdm(train_ds.index):\n",
    "    tf_train_data_chroma.loc[i]=[\"data/chroma/\" + str(i) + \".png\", genres[train_ds.loc[i]]]\n",
    "\n",
    "for i in tqdm(validation_ds.index):\n",
    "    tf_validation_data_chroma.loc[i]=[\"data/chroma//\" + str(i) + \".png\", genres[validation_ds.loc[i]]]\n",
    "\n",
    "for i in tqdm(test_ds.index):\n",
    "    tf_test_data_chroma.loc[i]=[\"data/chroma//\" + str(i) + \".png\", genres[test_ds.loc[i]]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(\n",
    "    rescale=1 / 255.,           # normalize pixel values between 0-1\n",
    "    vertical_flip=False,         # vertical transposition\n",
    "    horizontal_flip=True,       # horizontal transposition\n",
    "    rotation_range=0,\n",
    "    height_shift_range=0.3,     # shift the height of the image 30%\n",
    "    brightness_range=[0.1, 0.9] # specify the range in which to decrease/increase brightness\n",
    ")\n",
    "\n",
    "genX1 = generator.flow_from_dataframe(tf_train_data,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               shuffle=False,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               target_size=(174,484),\n",
    "                                               seed=42)\n",
    "genX2 = generator.flow_from_dataframe(tf_train_data_chroma,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               shuffle=False,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               target_size=(174,484),\n",
    "                                               seed=42)\n",
    "\n",
    "genX1val = generator.flow_from_dataframe(tf_validation_data,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               shuffle=False,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               target_size=(174,484),\n",
    "                                               seed=42)\n",
    "genX2val = generator.flow_from_dataframe(tf_validation_data_chroma,class_mode='raw',\n",
    "                                               x_col='Filename',\n",
    "                                               y_col = 'label',\n",
    "                                               shuffle=False,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               target_size=(174,484),\n",
    "                                               seed=42)\n",
    "\n",
    "def format_gen_outputs(gen1,gen2):\n",
    "    x1 = gen1[0]\n",
    "    x2 = gen2[0]\n",
    "    y1 = gen1[1]\n",
    "    return [x1, x2], y1\n",
    "\n",
    "traingen2 = map(format_gen_outputs, genX1, genX2)\n",
    "validationgen2 = map(format_gen_outputs, genX1val, genX2val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "\n",
    "def create_multiinput_model(width, height, depth, classes):\n",
    "    inputA = Input(shape=(height,width,depth))\n",
    "    inputB = Input(shape=(height,width,depth))\n",
    "\n",
    "    # the first branch operates on the first input\n",
    "    x = Resizing(128, 128)(inputA)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(5, 5), activation=\"relu\", name=\"X\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Model(inputs=inputA, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = Resizing(128, 128)(inputB)\n",
    "\n",
    "    y = Conv2D(64, kernel_size=(5, 5), activation=\"relu\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "\n",
    "    y = Flatten()(y)\n",
    "    y = Dense(100)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    y = Model(inputs=inputB, outputs=y)\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([x.output, y.output])\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    z = Dense(100)(combined)\n",
    "    z = Dense(classes, activation=\"softmax\")(z)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    md = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "    return md\n",
    "\n",
    "multi_model = create_multiinput_model(484, 174, 3, 8)\n",
    "\n",
    "multi_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(multi_model.summary())\n",
    "keras.utils.plot_model(multi_model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import Model\n",
    "\n",
    "def create_multi_model_kt(hp):\n",
    "    inputA = Input(shape=(484, 174, 3))\n",
    "    inputB = Input(shape=(484, 174, 3))\n",
    "\n",
    "    hp_size = hp.Int('size', min_value=128, max_value=512, step=128)\n",
    "\n",
    "    # the first branch operates on the first input\n",
    "    x = Resizing(hp_size, hp_size)(inputA)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(5, 5), activation=\"relu\", name=\"X\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    hp_units_x= hp.Int('units_x', min_value=10, max_value=100, step=10)\n",
    "    x = Dense(hp_units_x)(x)\n",
    "\n",
    "    hp_dropout_x = hp.Float('dropout_x', min_value=0.1, max_value=0.9, step=0.1)\n",
    "    x = Dropout(hp_dropout_x)(x)\n",
    "\n",
    "    x = Model(inputs=inputA, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = Resizing(hp_size, hp_size)(inputB)\n",
    "\n",
    "    y = Conv2D(64, kernel_size=(5, 5), activation=\"relu\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "\n",
    "    y = Flatten()(y)\n",
    "    hp_units_y= hp.Int('units_y', min_value=10, max_value=100, step=10)\n",
    "    y = Dense(hp_units_y)(y)\n",
    "    hp_dropout_y = hp.Float('dropout_y', min_value=0.1, max_value=0.9, step=0.1)\n",
    "    y = Dropout(hp_dropout_y)(y)\n",
    "    y = Model(inputs=inputB, outputs=y)\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([x.output, y.output])\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    hp_units_z= hp.Int('units_z', min_value=10, max_value=100, step=10)\n",
    "    z = Dense(hp_units_z)(combined)\n",
    "    z = Dense(8, activation=\"softmax\")(z)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    md = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    md.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return md\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(create_multi_model_kt,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir_multi',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(validationgen2, validation_data=validationgen2, epochs=10, callbacks=[stop_early], steps_per_epoch=len(tf_train_data)//BATCH_SIZE, validation_steps=len(tf_validation_data)//BATCH_SIZE)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "UnitsX: {best_hps.get('units_x')}\n",
    "DropoutX:{best_hps.get('dropout_x')}\n",
    "UnitsY: {best_hps.get('units_y')}\n",
    "DropoutY:{best_hps.get('dropout_y')}\n",
    "UnitsZ: {best_hps.get('units_z')}\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "Size: {best_hps.get('size')}\n",
    "\"\"\")\n",
    "\n",
    "multi_model_spec = tuner.hypermodel.build(best_hps)\n",
    "print(multi_model_spec.summary())\n",
    "keras.utils.plot_model(multi_model_spec, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validationgen2.__next__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#history = multi_model.fit_generator(traingen2, epochs=1, steps_per_epoch=1, validation_steps=2)\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "history = multi_model.fit(traingen2, epochs=10, validation_data=validationgen2, steps_per_epoch=len(tf_train_data)//BATCH_SIZE, validation_steps=len(tf_validation_data)//BATCH_SIZE, callbacks=[early_stop, PlotLossesKeras()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_model.evaluate(validationgen2, steps=25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}